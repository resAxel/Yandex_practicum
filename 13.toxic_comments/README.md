# Проект для «Викишоп» с BERT

Цель проекта: построить модель классификации комментариев на позитивные и негативные.  
Заказчик: интернет-магазин «Викишоп».

## Данные 
Набор данных с разметкой о токсичности правок. Столбец text содержит текст комментария, а toxic — целевой признак.

Значение метрики качества F1 не меньше 0.75.

## Зазачи

- Загрузить и подготовить данные.
- Обучить разные модели. Значение метрики качества F1 не меньше 0.75
- Сделать выводы.

## Используемые библиотеки
*pandas*  
*numpy*  
*sklearn*  
*nltk*  
*tqdm*  
*torch*  
*transformers*

## Статус проекта
Завершен

## Ключевой вывод/результат
- Построены 2 модели классификации коментариев на позитивные и негативные. В качестве модели классификации использована логистическая регрессия. 
- Для подготовки признаков (векторизации текста) использова лись 2 метода: первый основан на лемматизации и оценки важности слов TF-IDF, второй использовал обученную нейросеть BERT. 
- Метриики сильно зависят от размера обучающих данных. Чтоб получить заданные метрики пришлось использовать весь датасет. 
- Балансировка классов downsample или class_weight='balanced' понижает метрики. 
- Подбор параметров кроссвалидацией позворляет немного улучшить метрики, но на таком объема данных занимает очень много времени. 
- Модель логистической регрессии с TF-IDF признаками показала более высокие метрики чем модель BERT признаками.
